{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report\n",
    "from transformers import TOKENIZER_MAPPING, AutoModelForSequenceClassification, AutoTokenizer, AdamW, get_linear_schedule_with_warmup, XLMRobertaTokenizer, XLMRobertaForSequenceClassification\n",
    "import os\n",
    "from dataset import Dataset\n",
    "from util import create_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1 GPU(s) available.\n",
      "We will use the GPU:Tesla V100-SXM2-32GB (cuda)\n",
      "Texts: 35575\n",
      "Label names: Index(['Mixed_feelings', 'Negative', 'Positive', 'not-Tamil', 'unknown_state'], dtype='object')\n",
      "Texts: 3962\n",
      "Label names: Index(['Mixed_feelings', 'Negative', 'Positive', 'not-Tamil', 'unknown_state'], dtype='object')\n",
      "Texts: 5951\n",
      "Label names: Index(['Mixed feelings', 'Negative', 'Positive', 'not-Kannada',\n",
      "       'unknown state'],\n",
      "      dtype='object')\n",
      "Texts: 691\n",
      "Label names: Index(['Mixed feelings', 'Negative', 'Positive', 'not-Kannada',\n",
      "       'unknown state'],\n",
      "      dtype='object')\n",
      "Texts: 15726\n",
      "Label names: Index(['Mixed_feelings', 'Negative', 'Positive', 'not-malayalam',\n",
      "       'unknown_state'],\n",
      "      dtype='object')\n",
      "Texts: 1766\n",
      "Label names: Index(['Mixed_feelings', 'Negative', 'Positive', 'not-malayalam',\n",
      "       'unknown_state'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "TOKENIZER_NAME = \"sentence-transformers/paraphrase-xlm-r-multilingual-v1\"\n",
    "MODEL_NAME = \"sentence-transformers/paraphrase-xlm-r-multilingual-v1\"\n",
    "LEARNING_RATE = 3e-5\n",
    "\n",
    "#OUTPUT_FILE = \"NODUP-paraphrase-roberta-kan-pickle.md\"\n",
    "\n",
    "EPOCHS = 4\n",
    "BATCH_SIZE = 24 \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "\n",
    "if torch.cuda.is_available():    \n",
    "    device = torch.device(\"cuda\")\n",
    "    print('There are %d GPU(s) available.' % torch.cuda.device_count())    \n",
    "    print(f'We will use the GPU:{torch.cuda.get_device_name()} ({device})')\n",
    "\n",
    "else:\n",
    "    print('NO GPU AVAILABLE ERROR')\n",
    "    device = torch.device(\"cpu\")\n",
    "   \n",
    "tokenizer = AutoTokenizer.from_pretrained(TOKENIZER_NAME)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"../pickles_mixed/\", num_labels=5, output_attentions=True)\n",
    "model.to(device)\n",
    "optimizer = AdamW(model.parameters(), lr = LEARNING_RATE, no_deprecation_warning=True)\n",
    "\n",
    "data = Dataset()\n",
    "tam_train_2022,_, _, _, _,_ = data.get_fire_2022_dataset(tokenizer, balance=False)\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "            tam_train_2022,\n",
    "            sampler = RandomSampler(tam_train_2022),\n",
    "            batch_size = BATCH_SIZE)\n",
    "\n",
    "total_steps = len(train_dataloader) * EPOCHS\n",
    "\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
    "                                            num_warmup_steps = 0,\n",
    "                                            num_training_steps = total_steps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Texts: 35575\n",
      "Label names: Index(['Mixed_feelings', 'Negative', 'Positive', 'not-Tamil', 'unknown_state'], dtype='object')\n",
      "Texts: 3962\n",
      "Label names: Index(['Mixed_feelings', 'Negative', 'Positive', 'not-Tamil', 'unknown_state'], dtype='object')\n",
      "Texts: 5951\n",
      "Label names: Index(['Mixed feelings', 'Negative', 'Positive', 'not-Kannada',\n",
      "       'unknown state'],\n",
      "      dtype='object')\n",
      "Texts: 691\n",
      "Label names: Index(['Mixed feelings', 'Negative', 'Positive', 'not-Kannada',\n",
      "       'unknown state'],\n",
      "      dtype='object')\n",
      "Texts: 15726\n",
      "Label names: Index(['Mixed_feelings', 'Negative', 'Positive', 'not-malayalam',\n",
      "       'unknown_state'],\n",
      "      dtype='object')\n",
      "Texts: 1766\n",
      "Label names: Index(['Mixed_feelings', 'Negative', 'Positive', 'not-malayalam',\n",
      "       'unknown_state'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tam validation:   0%|          | 0/166 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tam validation: 3984\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tam validation: 100%|██████████| 166/166 [00:38<00:00,  4.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.22      0.33      0.26       289\n",
      "           1       0.41      0.44      0.42       453\n",
      "           2       0.82      0.75      0.78      2477\n",
      "           3       0.57      0.63      0.60       161\n",
      "           4       0.45      0.47      0.46       582\n",
      "\n",
      "    accuracy                           0.64      3962\n",
      "   macro avg       0.49      0.52      0.51      3962\n",
      "weighted avg       0.66      0.64      0.65      3962\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "OUTPUT_FILE = \"BIAOJSDOIJASD\"\n",
    "data.fire_validation(model, tokenizer, device, output_file=OUTPUT_FILE, year=2022, BS=BATCH_SIZE, dataset='tam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp-venv",
   "language": "python",
   "name": "myenv"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

## Info
This was trained on:
- [../data/new_tam_train.tsv](https://github.com/flippe3/fire_2022/tree/master/task_a/data/../data/new_tam_train.tsv)

validated on:
 - [../data/tam_sentiment_dev.tsv](https://github.com/flippe3/fire_2022/tree/master/task_a/data/../data/tam_sentiment_dev.tsv)

Model: [sentence-transformers/paraphrase-xlm-r-multilingual-v1](https://huggingface.co/sentence-transformers/paraphrase-xlm-r-multilingual-v1)

 Tokenizer: [sentence-transformers/paraphrase-xlm-r-multilingual-v1](https://huggingface.co/sentence-transformers/paraphrase-xlm-r-multilingual-v1)

Hyperparameters:
- Learning Rate: 3e-05
- Epochs: 4
- Batch Size: 24

 2022-07-27 00:31:50 
```
              precision    recall  f1-score   support

           0       0.11      0.42      0.17       110
           1       0.39      0.45      0.42       417
           2       0.89      0.70      0.79      2871
           3       0.51      0.73      0.60       123
           4       0.35      0.49      0.41       441

    accuracy                           0.65      3962
   macro avg       0.45      0.56      0.48      3962
weighted avg       0.75      0.65      0.68      3962
```

 2022-07-27 00:51:28 
```
              precision    recall  f1-score   support

           0       0.18      0.43      0.26       186
           1       0.34      0.52      0.41       319
           2       0.88      0.72      0.79      2738
           3       0.58      0.66      0.62       154
           4       0.44      0.47      0.46       565

    accuracy                           0.66      3962
   macro avg       0.48      0.56      0.51      3962
weighted avg       0.73      0.66      0.68      3962
```

 2022-07-27 01:11:09 
```
              precision    recall  f1-score   support

           0       0.20      0.37      0.26       237
           1       0.41      0.47      0.43       418
           2       0.83      0.74      0.78      2552
           3       0.57      0.64      0.60       159
           4       0.46      0.47      0.46       596

    accuracy                           0.64      3962
   macro avg       0.49      0.54      0.51      3962
weighted avg       0.68      0.64      0.66      3962
```

 2022-07-27 01:30:50 
```
              precision    recall  f1-score   support

           0       0.20      0.30      0.24       293
           1       0.44      0.44      0.44       479
           2       0.81      0.74      0.78      2469
           3       0.56      0.64      0.60       155
           4       0.43      0.46      0.45       566

    accuracy                           0.63      3962
   macro avg       0.49      0.52      0.50      3962
weighted avg       0.66      0.63      0.64      3962
```
## Info
This was trained on:
- [../data/new_tam_train.tsv](https://github.com/flippe3/fire_2022/tree/master/task_a/data/../data/new_tam_train.tsv)

validated on:
 - [../data/tam_sentiment_dev.tsv](https://github.com/flippe3/fire_2022/tree/master/task_a/data/../data/tam_sentiment_dev.tsv)

Model: [sentence-transformers/paraphrase-xlm-r-multilingual-v1](https://huggingface.co/sentence-transformers/paraphrase-xlm-r-multilingual-v1)

 Tokenizer: [sentence-transformers/paraphrase-xlm-r-multilingual-v1](https://huggingface.co/sentence-transformers/paraphrase-xlm-r-multilingual-v1)

Hyperparameters:
- Learning Rate: 3e-05
- Epochs: 4
- Batch Size: 24

 2022-07-27 10:05:19 
```
              precision    recall  f1-score   support

           0       0.14      0.45      0.22       140
           1       0.45      0.43      0.44       498
           2       0.89      0.70      0.78      2863
           3       0.56      0.68      0.61       145
           4       0.28      0.54      0.37       316

    accuracy                           0.64      3962
   macro avg       0.46      0.56      0.48      3962
weighted avg       0.75      0.64      0.68      3962
```

 2022-07-27 10:24:54 
```
              precision    recall  f1-score   support

           0       0.20      0.38      0.26       237
           1       0.36      0.52      0.43       334
           2       0.89      0.71      0.79      2816
           3       0.51      0.64      0.57       140
           4       0.38      0.53      0.44       435

    accuracy                           0.65      3962
   macro avg       0.47      0.56      0.50      3962
weighted avg       0.73      0.65      0.68      3962
```

 2022-07-27 10:44:27 
```
              precision    recall  f1-score   support

           0       0.24      0.33      0.27       314
           1       0.39      0.44      0.42       421
           2       0.83      0.74      0.78      2520
           3       0.56      0.64      0.60       152
           4       0.43      0.47      0.45       555

    accuracy                           0.63      3962
   macro avg       0.49      0.53      0.50      3962
weighted avg       0.67      0.63      0.65      3962
```

 2022-07-27 11:04:01 
```
              precision    recall  f1-score   support

 Mixed Feelings   0.22      0.33      0.26       289
       Negative   0.41      0.44      0.42       453
      Postitive   0.82      0.75      0.78      2477
      Not-Tamil   0.57      0.63      0.60       161
   unkown_state   0.45      0.47      0.46       582

    accuracy                           0.64      3962
   macro avg       0.49      0.52      0.51      3962
weighted avg       0.66      0.64      0.65      3962
```
## Info
This was trained on:
- [../data/new_tam_train.tsv](https://github.com/flippe3/fire_2022/tree/master/task_a/data/../data/new_tam_train.tsv)

validated on:
 - [../data/tam_sentiment_dev.tsv](https://github.com/flippe3/fire_2022/tree/master/task_a/data/../data/tam_sentiment_dev.tsv)

Model: [sentence-transformers/paraphrase-xlm-r-multilingual-v1](https://huggingface.co/sentence-transformers/paraphrase-xlm-r-multilingual-v1)

 Tokenizer: [sentence-transformers/paraphrase-xlm-r-multilingual-v1](https://huggingface.co/sentence-transformers/paraphrase-xlm-r-multilingual-v1)

Hyperparameters:
- Learning Rate: 3e-05
- Epochs: 4
- Batch Size: 24
## Info
This was trained on:
- [../data/new_tam_train.tsv](https://github.com/flippe3/fire_2022/tree/master/task_a/data/../data/new_tam_train.tsv)

validated on:
 - [../data/tam_sentiment_dev.tsv](https://github.com/flippe3/fire_2022/tree/master/task_a/data/../data/tam_sentiment_dev.tsv)

Model: [sentence-transformers/paraphrase-xlm-r-multilingual-v1](https://huggingface.co/sentence-transformers/paraphrase-xlm-r-multilingual-v1)

 Tokenizer: [sentence-transformers/paraphrase-xlm-r-multilingual-v1](https://huggingface.co/sentence-transformers/paraphrase-xlm-r-multilingual-v1)

Hyperparameters:
- Learning Rate: 3e-05
- Epochs: 4
- Batch Size: 24

 2022-08-17 11:02:08 
```
              precision    recall  f1-score   support

           0       0.09      0.47      0.16        87
           1       0.41      0.47      0.44       424
           2       0.91      0.69      0.78      2970
           3       0.42      0.66      0.51       112
           4       0.32      0.52      0.39       369

    accuracy                           0.64      3962
   macro avg       0.43      0.56      0.46      3962
weighted avg       0.77      0.64      0.69      3962
```

 2022-08-17 11:32:41 
```
              precision    recall  f1-score   support

           0       0.17      0.35      0.23       220
           1       0.38      0.48      0.43       378
           2       0.87      0.72      0.79      2747
           3       0.47      0.53      0.50       157
           4       0.39      0.52      0.44       460

    accuracy                           0.64      3962
   macro avg       0.46      0.52      0.48      3962
weighted avg       0.71      0.64      0.67      3962
```
## Info
This was trained on:
- [../data/new_tam_train.tsv](https://github.com/flippe3/fire_2022/tree/master/task_a/data/../data/new_tam_train.tsv)

validated on:
 - [../data/tam_sentiment_dev.tsv](https://github.com/flippe3/fire_2022/tree/master/task_a/data/../data/tam_sentiment_dev.tsv)

Model: [bert-base-multilingual-cased](https://huggingface.co/bert-base-multilingual-cased)

 Tokenizer: [bert-base-multilingual-cased](https://huggingface.co/bert-base-multilingual-cased)

Hyperparameters:
- Learning Rate: 3e-05
- Epochs: 4
- Batch Size: 24
## Info
This was trained on:
- [../data/new_tam_train.tsv](https://github.com/flippe3/fire_2022/tree/master/task_a/data/../data/new_tam_train.tsv)

validated on:
 - [../data/tam_sentiment_dev.tsv](https://github.com/flippe3/fire_2022/tree/master/task_a/data/../data/tam_sentiment_dev.tsv)

Model: [bert-base-multilingual-cased](https://huggingface.co/bert-base-multilingual-cased)

 Tokenizer: [bert-base-multilingual-cased](https://huggingface.co/bert-base-multilingual-cased)

Hyperparameters:
- Learning Rate: 3e-05
- Epochs: 4
- Batch Size: 16

 2022-08-17 12:03:14 
```
              precision    recall  f1-score   support

           0       0.15      0.35      0.21       187
           1       0.46      0.42      0.44       527
           2       0.84      0.73      0.78      2591
           3       0.51      0.53      0.52       170
           4       0.40      0.50      0.44       487

    accuracy                           0.63      3962
   macro avg       0.47      0.51      0.48      3962
weighted avg       0.69      0.63      0.66      3962
```

 2022-08-17 12:14:57 
```
              precision    recall  f1-score   support

           0       0.09      0.51      0.15        79
           1       0.21      0.48      0.29       205
           2       0.88      0.68      0.77      2947
           3       0.43      0.80      0.56        95
           4       0.44      0.42      0.43       636

    accuracy                           0.62      3962
   macro avg       0.41      0.58      0.44      3962
weighted avg       0.75      0.62      0.67      3962
```

 2022-08-17 12:34:40 
```
              precision    recall  f1-score   support

           0       0.15      0.39      0.22       166
           1       0.36      0.49      0.42       359
           2       0.86      0.73      0.79      2654
           3       0.63      0.58      0.60       193
           4       0.43      0.45      0.44       590

    accuracy                           0.64      3962
   macro avg       0.49      0.53      0.49      3962
weighted avg       0.71      0.64      0.67      3962
```

 2022-08-17 12:45:30 
```
              precision    recall  f1-score   support

           0       0.23      0.27      0.25       371
           1       0.36      0.42      0.39       406
           2       0.79      0.74      0.77      2411
           3       0.54      0.51      0.52       187
           4       0.44      0.46      0.45       587

    accuracy                           0.61      3962
   macro avg       0.47      0.48      0.48      3962
weighted avg       0.63      0.61      0.62      3962
```

 2022-08-17 12:54:22 
```
              precision    recall  f1-score   support

           0       0.19      0.31      0.24       271
           1       0.36      0.50      0.42       345
           2       0.85      0.73      0.78      2619
           3       0.57      0.62      0.59       161
           4       0.44      0.47      0.45       566

    accuracy                           0.64      3962
   macro avg       0.48      0.53      0.50      3962
weighted avg       0.69      0.64      0.66      3962
```

 2022-08-17 13:14:09 
```
              precision    recall  f1-score   support

           0       0.19      0.32      0.24       263
           1       0.41      0.43      0.42       452
           2       0.83      0.74      0.78      2531
           3       0.57      0.60      0.58       167
           4       0.42      0.47      0.44       549

    accuracy                           0.63      3962
   macro avg       0.48      0.51      0.49      3962
weighted avg       0.67      0.63      0.65      3962
```

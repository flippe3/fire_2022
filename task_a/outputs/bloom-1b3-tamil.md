## Info
This was trained on:
- [../data/tam_sentiment_train.tsv](https://github.com/flippe3/fire_2022/tree/master/task_a/data/../data/tam_sentiment_train.tsv)

validated on:
 - [../data/tam_sentiment_dev.tsv](https://github.com/flippe3/fire_2022/tree/master/task_a/data/../data/tam_sentiment_dev.tsv)

Model: [bigscience/bloom-1b3](https://huggingface.co/bigscience/bloom-1b3)

 Tokenizer: [bigscience/bloom-1b3](https://huggingface.co/bigscience/bloom-1b3)

Hyperparameters:
- Learning Rate: 3e-05
- Epochs: 4
- Batch Size: 24
## Info
This was trained on:
- [../data/tam_sentiment_train.tsv](https://github.com/flippe3/fire_2022/tree/master/task_a/data/../data/tam_sentiment_train.tsv)

validated on:
 - [../data/tam_sentiment_dev.tsv](https://github.com/flippe3/fire_2022/tree/master/task_a/data/../data/tam_sentiment_dev.tsv)

Model: [bigscience/bloom-1b3](https://huggingface.co/bigscience/bloom-1b3)

 Tokenizer: [bigscience/bloom-1b3](https://huggingface.co/bigscience/bloom-1b3)

Hyperparameters:
- Learning Rate: 3e-05
- Epochs: 4
- Batch Size: 24
## Info
This was trained on:
- [../data/tam_sentiment_train.tsv](https://github.com/flippe3/fire_2022/tree/master/task_a/data/../data/tam_sentiment_train.tsv)

validated on:
 - [../data/tam_sentiment_dev.tsv](https://github.com/flippe3/fire_2022/tree/master/task_a/data/../data/tam_sentiment_dev.tsv)

Model: [bigscience/bloom-1b3](https://huggingface.co/bigscience/bloom-1b3)

 Tokenizer: [bigscience/bloom-1b3](https://huggingface.co/bigscience/bloom-1b3)

Hyperparameters:
- Learning Rate: 3e-05
- Epochs: 4
- Batch Size: 24
## Info
This was trained on:
- [../data/tam_sentiment_train.tsv](https://github.com/flippe3/fire_2022/tree/master/task_a/data/../data/tam_sentiment_train.tsv)

validated on:
 - [../data/tam_sentiment_dev.tsv](https://github.com/flippe3/fire_2022/tree/master/task_a/data/../data/tam_sentiment_dev.tsv)

Model: [bigscience/bloom-760m](https://huggingface.co/bigscience/bloom-760m)

 Tokenizer: [bigscience/bloom-760m](https://huggingface.co/bigscience/bloom-760m)

Hyperparameters:
- Learning Rate: 3e-05
- Epochs: 4
- Batch Size: 24
## Info
This was trained on:
- [../data/tam_sentiment_train.tsv](https://github.com/flippe3/fire_2022/tree/master/task_a/data/../data/tam_sentiment_train.tsv)

validated on:
 - [../data/tam_sentiment_dev.tsv](https://github.com/flippe3/fire_2022/tree/master/task_a/data/../data/tam_sentiment_dev.tsv)

Model: [bigscience/bloom-350m](https://huggingface.co/bigscience/bloom-350m)

 Tokenizer: [bigscience/bloom-350m](https://huggingface.co/bigscience/bloom-350m)

Hyperparameters:
- Learning Rate: 3e-05
- Epochs: 4
- Batch Size: 24

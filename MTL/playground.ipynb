{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer, AdamW, get_linear_schedule_with_warmup, XLMRobertaTokenizer, XLMRobertaForSequenceClassification\n",
    "import os\n",
    "from dataset import MTL_Dataset\n",
    "import transformers\n",
    "from model import MultitaskModel\n",
    "from data_trainer import *\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 3 GPU(s) available.\n",
      "We will use the GPU:Tesla V100-SXM2-32GB (cuda)\n"
     ]
    }
   ],
   "source": [
    "LEARNING_RATE = 3e-5\n",
    "\n",
    "EPOCHS = 4\n",
    "BATCH_SIZE = 24\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"2,3,4\"\n",
    "\n",
    "if torch.cuda.is_available():    \n",
    "    device = torch.device(\"cuda\")\n",
    "    print('There are %d GPU(s) available.' % torch.cuda.device_count())    \n",
    "    print(f'We will use the GPU:{torch.cuda.get_device_name()} ({device})')\n",
    "\n",
    "else:\n",
    "    print('NO GPU AVAILABLE ERROR')\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('sentence-transformers/paraphrase-xlm-r-multilingual-v1')\n",
    "\n",
    "model_name = \"sentence-transformers/paraphrase-xlm-r-multilingual-v1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at sentence-transformers/paraphrase-xlm-r-multilingual-v1 were not used when initializing XLMRobertaForSequenceClassification: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "- This IS expected if you are initializing XLMRobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at sentence-transformers/paraphrase-xlm-r-multilingual-v1 and are newly initialized: ['classifier.dense.weight', 'classifier.out_proj.weight', 'classifier.dense.bias', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of the model checkpoint at sentence-transformers/paraphrase-xlm-r-multilingual-v1 were not used when initializing XLMRobertaForSequenceClassification: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "- This IS expected if you are initializing XLMRobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at sentence-transformers/paraphrase-xlm-r-multilingual-v1 and are newly initialized: ['classifier.dense.weight', 'classifier.out_proj.weight', 'classifier.dense.bias', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of the model checkpoint at sentence-transformers/paraphrase-xlm-r-multilingual-v1 were not used when initializing XLMRobertaForSequenceClassification: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "- This IS expected if you are initializing XLMRobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at sentence-transformers/paraphrase-xlm-r-multilingual-v1 and are newly initialized: ['classifier.dense.weight', 'classifier.out_proj.weight', 'classifier.dense.bias', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "multitask_model = MultitaskModel.create(\n",
    "    model_name=model_name,\n",
    "    model_type_dict={\n",
    "        #\"kan_sentiment\": transformers.AutoModelForSequenceClassification,\n",
    "        #\"mal_sentiment\": transformers.AutoModelForSequenceClassification,\n",
    "        \"tam_sentiment\": transformers.AutoModelForSequenceClassification,\n",
    "        # \"eng_phobia\": transformers.AutoModelForSequenceClassification,\n",
    "         \"tam_phobia\": transformers.AutoModelForSequenceClassification,\n",
    "        # \"mal_phobia\": transformers.AutoModelForSequenceClassification,\n",
    "        # \"eng_tam_phobia\": transformers.AutoModelForSequenceClassification\n",
    "    },\n",
    "    model_config_dict={\n",
    "        #\"kan_sentiment\": transformers.AutoConfig.from_pretrained(model_name, num_labels=5),\n",
    "        #\"mal_sentiment\": transformers.AutoConfig.from_pretrained(model_name, num_labels=5),\n",
    "        \"tam_sentiment\": transformers.AutoConfig.from_pretrained(model_name, num_labels=5),\n",
    "        # \"eng_phobia\": transformers.AutoConfig.from_pretrained(model_name, num_labels=3),\n",
    "         \"tam_phobia\": transformers.AutoConfig.from_pretrained(model_name, num_labels=3),\n",
    "        # \"mal_phobia\": transformers.AutoConfig.from_pretrained(model_name, num_labels=3),\n",
    "        # \"eng_tam_phobia\": transformers.AutoConfig.from_pretrained(model_name, num_labels=3)\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default\n",
      "Using custom data configuration default\n",
      "Using custom data configuration default\n"
     ]
    }
   ],
   "source": [
    "dataset_dict = {\n",
    "    'kan_sentiment': nlp.load_dataset('csv', delimiter='\\t', data_files={'train': \"../task_a/data/new_kan_train.tsv\", 'test': \"../task_a/data/kan_sentiment_dev.tsv\"}),\n",
    "    'mal_sentiment': nlp.load_dataset('csv', delimiter='\\t', data_files={'train': \"../task_a/data/new_mal_train.tsv\", 'test': \"../task_a/data/Mal_sentiment_dev.tsv\"}),\n",
    "    'tam_sentiment': nlp.load_dataset('csv', delimiter='\\t', data_files={'train': \"../task_a/data/new_tam_train.tsv\", 'test': \"../task_a/data/tam_sentiment_dev.tsv\"}),\n",
    "\n",
    "#    'eng_phobia': nlp.load_dataset('csv', delimiter='\\t', data_files={'train': \"../task_b/data/eng_3_train.tsv\", 'test': \"../task_b/data/eng_3_dev.tsv\"}),\n",
    "#    'tam_phobia': nlp.load_dataset('csv', delimiter='\\t', data_files={'train': \"../task_b/data/new_tam_train.tsv\", 'test': \"../task_b/data/tam_3_dev.tsv\"}),\n",
    "#    'mal_phobia': nlp.load_dataset('csv', delimiter='\\t', data_files={'train': \"../task_b/data/new_mal_train.tsv\", 'test': \"../task_b/data/mal_3_dev.tsv\"}),\n",
    "#    'eng_tam_phobia': nlp.load_dataset('csv', delimiter='\\t', data_files={'train': \"../task_b/data/new_eng_tam_train.tsv\", 'test': \"../task_b/data/eng-tam_3_dev.tsv\"}),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_mal(example_batch):\n",
    "    features = {}\n",
    "    features = tokenizer.batch_encode_plus(\n",
    "                                    example_batch['text'],            \n",
    "                                    add_special_tokens = True,\n",
    "                                    max_length = 512,\n",
    "                                    padding = 'max_length',\n",
    "                                    return_attention_mask = True,\n",
    "                                    truncation=True)\n",
    "    new_labels = []\n",
    "    for i in example_batch['category']:\n",
    "        if i == \"Positive\":\n",
    "            new_labels.append(0)\n",
    "        elif i == \"Negative\":\n",
    "            new_labels.append(1)\n",
    "        elif i == \"not-malayalam\":\n",
    "            new_labels.append(2)\n",
    "        elif i == \"unknown_state\":\n",
    "            new_labels.append(3)\n",
    "        elif i == \"Mixed_feelings\":\n",
    "            new_labels.append(4)\n",
    "        else:\n",
    "            print(\"Error\", i, len(i))\n",
    "    features[\"labels\"] = new_labels\n",
    "    return features\n",
    "    \n",
    "def convert_to_kan(example_batch):\n",
    "    features = {}\n",
    "    features = tokenizer.batch_encode_plus(\n",
    "                                    example_batch['text'],            \n",
    "                                    add_special_tokens = True,\n",
    "                                    max_length = 512,\n",
    "                                    padding = 'max_length',\n",
    "                                    return_attention_mask = True,\n",
    "                                    truncation=True)\n",
    "    new_labels = []\n",
    "    for i in example_batch['category']:\n",
    "        if i == \"Positive\":\n",
    "            new_labels.append(0)\n",
    "        elif i == \"Negative\":\n",
    "            new_labels.append(1)\n",
    "        elif i == \"not-Kannada\":\n",
    "            new_labels.append(2)\n",
    "        elif i == \"unknown state\":\n",
    "            new_labels.append(3)\n",
    "        elif i == \"Mixed feelings\":\n",
    "            new_labels.append(4)\n",
    "        else:\n",
    "            print(\"Error\", i)\n",
    "\n",
    "    features[\"labels\"] = new_labels \n",
    "    return features\n",
    "\n",
    "def convert_to_tam(example_batch):\n",
    "    features = {}\n",
    "    features = tokenizer.batch_encode_plus(\n",
    "                                    example_batch['text'],            \n",
    "                                    add_special_tokens = True,\n",
    "                                    max_length = 512,\n",
    "                                    padding = 'max_length',\n",
    "                                    return_attention_mask = True,\n",
    "                                    truncation=True)\n",
    "    new_labels = []\n",
    "    for i in example_batch['category']:\n",
    "        if i == \"Positive\":\n",
    "            new_labels.append(0)\n",
    "        elif i == \"Negative\":\n",
    "            new_labels.append(1)\n",
    "        elif i == \"not-Tamil\":\n",
    "            new_labels.append(2)\n",
    "        elif i == \"unknown_state\":\n",
    "            new_labels.append(3)\n",
    "        elif i == \"Mixed_feelings\":\n",
    "            new_labels.append(4)\n",
    "        else:\n",
    "            print(\"Error\", i)\n",
    "\n",
    "    features[\"labels\"] = new_labels \n",
    "    return features\n",
    "\n",
    "def convert_to_phobia(example_batch):\n",
    "    features = {}\n",
    "    features = tokenizer.batch_encode_plus(\n",
    "                                    example_batch['text'],            \n",
    "                                    add_special_tokens = True,\n",
    "                                    max_length = 512,\n",
    "                                    padding = 'max_length',\n",
    "                                    return_attention_mask = True,\n",
    "                                    truncation=True)\n",
    "    new_labels = []\n",
    "    for i in example_batch['category']:\n",
    "        if i == \"Non-anti-LGBT+ content\":\n",
    "            new_labels.append(0)\n",
    "        elif i == \"Homophobic\":\n",
    "            new_labels.append(1)\n",
    "        elif i == \"Transphobic\":\n",
    "            new_labels.append(2)\n",
    "        else:\n",
    "            print(\"Error\", i)\n",
    "\n",
    "    features[\"labels\"] = new_labels \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_func_dict = {\n",
    "    #\"kan_sentiment\": convert_to_kan,\n",
    "    #\"mal_sentiment\": convert_to_mal,\n",
    "    \"tam_sentiment\": convert_to_tam,\n",
    "    # \"eng_phobia\": convert_to_phobia,\n",
    "    \"tam_phobia\": convert_to_phobia,\n",
    "    # \"mal_phobia\": convert_to_phobia,\n",
    "    # \"eng_tam_phobia\": convert_to_phobia,\n",
    "}\n",
    "\n",
    "columns_dict = {\n",
    "    #\"kan_sentiment\": ['input_ids', 'attention_mask', 'labels'],\n",
    "    #\"mal_sentiment\": ['input_ids', 'attention_mask', 'labels'],\n",
    "    \"tam_sentiment\": ['input_ids', 'attention_mask', 'labels'],\n",
    "    \n",
    "    # \"eng_phobia\": ['input_ids', 'attention_mask', 'labels'],\n",
    "     \"tam_phobia\": ['input_ids', 'attention_mask', 'labels'],\n",
    "    # \"mal_phobia\": ['input_ids', 'attention_mask', 'labels'],\n",
    "    # \"eng_tam_phobia\": ['input_ids', 'attention_mask', 'labels'],\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2bc4c667b2145bc82199f813458e228",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=6.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "kan_sentiment train 5951 5951\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a91836eb78b4ce8adf80fd72f5b9243",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "kan_sentiment test 691 691\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d0eab55f59a4414b75b5ad118453655",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=16.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "mal_sentiment train 15726 15726\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65f844f45dc04bd5ae5533751779b5a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "mal_sentiment test 1766 1766\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2ba1f277c6a481e9e829405d0c23da0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=36.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "tam_sentiment train 35575 35575\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62db7fab34eb49ef9f9a0381ef5154e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=4.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "tam_sentiment test 3962 3962\n"
     ]
    }
   ],
   "source": [
    "features_dict = {}\n",
    "for task_name, dataset in dataset_dict.items():\n",
    "    features_dict[task_name] = {}\n",
    "    for phase, phase_dataset in dataset.items():\n",
    "        features_dict[task_name][phase] = phase_dataset.map(\n",
    "            convert_func_dict[task_name],\n",
    "            batched=True,\n",
    "            load_from_cache_file=False,\n",
    "        )\n",
    "        features_dict[task_name][phase].set_format(\n",
    "            type=\"torch\", \n",
    "            columns=columns_dict[task_name],\n",
    "        )\n",
    "        print(task_name, phase, len(phase_dataset), len(features_dict[task_name][phase]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = {\n",
    "\t\ttask_name: dataset[\"train\"] for task_name, dataset in features_dict.items()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/filnil/nlp/lib/python3.6/site-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  FutureWarning,\n",
      "***** Running training *****\n",
      "  Num examples = 57252\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 32\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 96\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1791\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kan_sentiment 5951 96 <torch.utils.data.dataloader.DataLoader object at 0x7fb780011128>\n",
      "mal_sentiment 15726 96 <torch.utils.data.dataloader.DataLoader object at 0x7fb400f76208>\n",
      "tam_sentiment 35575 96 <torch.utils.data.dataloader.DataLoader object at 0x7fb400f76ba8>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/torch/nn/parallel/_functions.py:65: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1791' max='1791' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1791/1791 39:44, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>1.143100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.955400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.897100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1791, training_loss=0.9765373668745202, metrics={'train_runtime': 2392.0489, 'train_samples_per_second': 71.803, 'train_steps_per_second': 0.749, 'total_flos': 4.581941053475635e+16, 'train_loss': 0.9765373668745202, 'epoch': 3.0})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer = MultitaskTrainer(\n",
    "    model=multitask_model,\n",
    "    args=transformers.TrainingArguments(\n",
    "        output_dir=\"output_trainer\",\n",
    "        overwrite_output_dir=True,\n",
    "        learning_rate=1e-5,\n",
    "        do_train=True,\n",
    "        num_train_epochs=3,\n",
    "        per_device_train_batch_size=32,\n",
    "        save_steps=3000,\n",
    "    ),\n",
    "    data_collator=NLPDataCollator(),\n",
    "    train_dataset=train_dataset,\n",
    ")\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting validation tam_sentiment\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'DataLoaderWithTaskname' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-92e36eccf365>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtask_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"tam_sentiment\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"tam_phobia\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Starting validation\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtask_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     eval_dataloader = DataLoaderWithTaskname(\n\u001b[0m\u001b[1;32m      5\u001b[0m         \u001b[0mtask_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_eval_dataloader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meval_dataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeatures_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtask_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"test\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'DataLoaderWithTaskname' is not defined"
     ]
    }
   ],
   "source": [
    "preds_dict = {}\n",
    "for task_name in [\"tam_sentiment\", \"tam_phobia\"]:\n",
    "    print(\"Starting validation\", task_name)\n",
    "    eval_dataloader = DataLoaderWithTaskname(\n",
    "        task_name,\n",
    "        trainer.get_eval_dataloader(eval_dataset=features_dict[task_name][\"test\"])\n",
    "    )\n",
    "    print(eval_dataloader.data_loader.collate_fn)\n",
    "    preds_dict[task_name] = trainer.evaluation_loop(\n",
    "        eval_dataloader,\n",
    "        description=f\"Validation: {task_name}\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mal Sentiment:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.69      0.75       836\n",
      "           1       0.50      0.52      0.51       226\n",
      "           2       0.78      0.75      0.76       147\n",
      "           3       0.69      0.72      0.70       557\n",
      "           4       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.68      1766\n",
      "   macro avg       0.56      0.54      0.55      1766\n",
      "weighted avg       0.74      0.68      0.71      1766\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "preds = np.argmax(preds_dict['mal_sentiment'].predictions ,axis=1)\n",
    "ground_truth = features_dict['mal_sentiment']['test']['labels']\n",
    "\n",
    "print(\"Mal Sentiment:\\n\", classification_report(preds, ground_truth))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tam Sentiment:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.71      0.79      2784\n",
      "           1       0.41      0.45      0.43       435\n",
      "           2       0.48      0.64      0.55       133\n",
      "           3       0.37      0.46      0.41       489\n",
      "           4       0.12      0.44      0.19       121\n",
      "\n",
      "    accuracy                           0.64      3962\n",
      "   macro avg       0.45      0.54      0.47      3962\n",
      "weighted avg       0.73      0.64      0.67      3962\n",
      "\n"
     ]
    }
   ],
   "source": [
    "preds = np.argmax(preds_dict['tam_sentiment'].predictions ,axis=1)\n",
    "ground_truth = features_dict['tam_sentiment']['test']['labels']\n",
    "\n",
    "print(\"Tam Sentiment:\\n\", classification_report(preds, ground_truth))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kan Sentiment:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.68      0.73       366\n",
      "           1       0.60      0.58      0.59       146\n",
      "           2       0.75      0.62      0.67       133\n",
      "           3       0.36      0.54      0.43        46\n",
      "           4       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.64       691\n",
      "   macro avg       0.50      0.48      0.49       691\n",
      "weighted avg       0.71      0.64      0.67       691\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "preds = np.argmax(preds_dict['kan_sentiment'].predictions ,axis=1)\n",
    "ground_truth = features_dict['kan_sentiment']['test']['labels']\n",
    "\n",
    "print(\"Kan Sentiment:\\n\", classification_report(preds, ground_truth))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp-venv",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
